{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+Arqp4vkQ33NWvdDfEiWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogersm92/Machine_Learning/blob/main/Introduction_to_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXdq9dV_cwzP"
      },
      "source": [
        "# Neural Networks\r\n",
        "**Neural networks** are a means of doing machine learning, in which a computer learns to **perform some task by analyzing training examples**. \r\n",
        "They consist of thousands or even millions of simple processing nodes that are densely interconnected, called **neurons**. \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3uKNZGfk4f"
      },
      "source": [
        "# Neurons\r\n",
        "**Neurons** are the basic unit of a **Neural Network**. \r\n",
        "<br/><br/> They:\r\n",
        "1. Take some **inputs**.\r\n",
        "2. Perform a **mathematical operation**.\r\n",
        "3. Produce one **output**.\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1ha3dG0fpAeRbctEvW9q4_ZN8FC8G5loW)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QtbazfHl_KB"
      },
      "source": [
        "#Sigmoid Function\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1OfDSa6jMjaSgZfS5oATuwnZZPWVs85tm)\r\n",
        "\r\n",
        "A **Sigmoid function** is a mathematical function which has a characteristic S-shaped curve. There are a number of common sigmoid functions, such as the logistic function, the hyperbolic tangent, and the arctangent\r\n",
        "\r\n",
        "In machine learning, this term is normally used to refer specifically to the **logistic function**, also called the **logistic sigmoid function**.\r\n",
        "All sigmoid functions have the property that they map the entire number line into a small range such as **between 0 and 1, or -1 and 1**, so one use of a sigmoid function is to convert a real value into one that can be interpreted as a **probability**.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvjy0twkvcBg"
      },
      "source": [
        "#Coding a Neuron using the Sigmoid Function\r\n",
        "\r\n",
        "I'll use the fundamental package for scientific computing with Python: numpy\r\n",
        "\r\n",
        "Before I begin, we have to have this in mind: **Weights** and **biases** (commonly referred to as w and b) are the learnable parameters of a machine learning model. \r\n",
        "<br/><br/>\r\n",
        "\r\n",
        "Therefore, given an 'X' value, f(X) = Σ (weight * input) + bias.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QO-Es9nrvbO5",
        "outputId": "eaa1e03f-0761-42b3-c436-b67613e536d6"
      },
      "source": [
        "import numpy as np\r\n",
        "np.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.19.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLziucySv-zu"
      },
      "source": [
        "# Constructor class \r\n",
        "class Neuron:\r\n",
        "    def __init__(self, weights, bias):\r\n",
        "      self.weights = weights\r\n",
        "      self.bias = bias # Bias is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\r\n",
        "    \r\n",
        "    def feedforward(self, inputs): # inputs refer to 'x' values we will provide\r\n",
        "      # Weight inputs, add bias, then use the activation function\r\n",
        "      total = np.dot(self.weights, inputs) + self.bias # Dot product of two arrays. This method multiplies 2 arrays --> (w · x) + b = ((w1 · x1) + (w2 · x2)) + b\r\n",
        "      return sigmoid(total)\r\n",
        "\r\n",
        "# Sigmoid method\r\n",
        "def sigmoid(x):\r\n",
        "  return 1 / (1 + np.exp(-x)) # This line of code corresponds to the logistic Sigmoid function, see above\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mIuCHa26efP",
        "outputId": "e6634fdd-df4a-4713-a19a-29dd3aac6e63"
      },
      "source": [
        "# in this case, the weight will be [0, 1] and the bias will be 4\r\n",
        "weight = np.array([0, 1])\r\n",
        "bias = 4\r\n",
        "\r\n",
        "# I create a single neuron, like an instance of Neuron class\r\n",
        "neuron = Neuron(weight, bias)\r\n",
        "\r\n",
        "# I'll provide an input with the value [1, 5]\r\n",
        "x_input = np.array([1, 5])\r\n",
        "# Note: x_input = [1, 5] would mean x_input is a List, but we are working with Arrays here.\r\n",
        "print(neuron.feedforward(x_input)) # I access the feedforward methon that all Neuron instancies have (Object Orientation Programming)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9998766054240137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzlZCbV48p6H"
      },
      "source": [
        "# Just one neuron isn't enough\r\n",
        "In order to create a Neural Network, we need **multiple neurons**. \r\n",
        "<br></br>\r\n",
        "A neural network is nothing more than a bunch of neurons connected together. \r\n",
        "<br></br>\r\n",
        "Each neuron is **connected with all** previous inputs / outputs or other hidden layer neurons \r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1EkFtft1H7LzKzx0a31VyFB7KYNWEEcfv)\r\n",
        "\r\n",
        "A **hidden layer** is any layer between the input (first) layer and output (last) layer. There can be multiple hidden layers\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=10QUkBRrzXksboEZegSoxrNCwliJhegJX)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZOKwcNVB13X"
      },
      "source": [
        "# Coding a Neural Network\r\n",
        "\r\n",
        "I'll code a neural Network consisting in 2 inputs, 2 neurons within the hidden layer and 1 neuron within the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jitSx1bH9pt7",
        "outputId": "a50635dd-718d-4d1f-f0cd-aaa07ece75cf"
      },
      "source": [
        "# Previous code should be here, but thanks to Jupyter notebook it's not necessary\r\n",
        "\r\n",
        "class NeuralNetwork():\r\n",
        "  # an input layer with 2 inputs (inputs are not neurons)\r\n",
        "  # a hidden layer with 2 neurons\r\n",
        "  # an output layer with 1 neuron\r\n",
        "  # each neuron will have the same weight and bias\r\n",
        "  # weight [0, 1]\r\n",
        "  # bias = 0\r\n",
        "    def __init__(self):\r\n",
        "        weights = np.array([0, 1])\r\n",
        "        bias = 0\r\n",
        "\r\n",
        "        self.hidden_1 = Neuron(weights, bias)\r\n",
        "        self.hidden_2 = Neuron(weights, bias)\r\n",
        "        self.o1 = Neuron(weights, bias)\r\n",
        "\r\n",
        "    def feedforward(self, x):\r\n",
        "        output_h1 = self.hidden_1.feedforward(x)\r\n",
        "        output_h2 = self.hidden_2.feedforward(x)\r\n",
        "\r\n",
        "        # The inputs for output1 are the outputs from hidde_n1 and hidden_2\r\n",
        "        output_o1 = self.o1.feedforward(np.array([output_h1, output_h2]))\r\n",
        "\r\n",
        "        return output_o1\r\n",
        "\r\n",
        "network = NeuralNetwork()\r\n",
        "x = np.array([2, 3])\r\n",
        "print(network.feedforward(x)) # 0.7216325609518421"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7216325609518421\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}